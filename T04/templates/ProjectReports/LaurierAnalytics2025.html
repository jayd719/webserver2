<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Video Processing & Highlight
        Generation</title>
</head>
<style>
    body {
        font-family: 'Helvetica Neue', Arial, sans-serif;
    }
</style>

<body>
    <main>
        <h1>Design Specification Document for</h1>
        <span class="text-6xl mb-[50px] font-bold">Video Processing & Highlight
            Generation</span>
        <hr>

        <div>
            <video class="rounded-xl" src="Images/FinalOutput.mp4" type="video/mp4"></video>
        </div>
        <h2>Introduction</h2>
        <p>This document outlines the design and functionality of the next version of the video processing application,
            Clip Genius. The application now includes advanced features such as scoreboard detection, score extraction
            using Optical Character Recognition (OCR), and real-time video frame analysis. It is designed to process
            full lenght games to generate highlight clips.</p>
        <p>The primary users of this software would be oranizations that hold the rights to publish content for their
            teams on
            platforms such as their websites and social media.</p>

        <h2>Usage</h2>
        <img src="Images/CLIP_GENIUS.svg" alt="">
        <pre>python main.py &lt;video_path&gt; --function &lt;function_name&gt;</pre>
        <h3>Arguments</h3>
        <ul>
            <li>
                <p><code>video_path</code>: Path to the video file to be processed.</p>
            </li>
            <li>
                <p><code>--function</code>: Specifies the processing function to use. Valid options are:</p>
                <ul>
                    <li>
                        <p><code>PROCESS_VIDEO</code></p>
                    </li>
                    <li>
                        <p><code>PROCESS_FILE</code></p>
                    </li>
                    <li>
                        <p><code>PROCESS_FILE_MULTI_THREAD</code></p>
                    </li>
                </ul>
            </li>
        </ul>
        <h3>Dependencies</h3>
        <ul>
            <li><code>argparse</code>: Command-line argument parsing.</li>
            <li><code>OpenCV (cv2)</code>: Video/image processing.</li>
            <li><code>pytesseract</code>: OCR for score extraction.</li>
            <li><code>numpy</code>: Numerical operations.</li>
            <li><code>re</code>: Regex text processing.</li>
            <li><code>subprocess</code>: Running FFmpeg commands.</li>
            <li><code>os</code>: File/directory operations.</li>
            <li><code>json</code>: Parsing FFprobe output.</li>
            <li><code>time</code>: Timestamp formatting.</li>
            <li><code>threading</code>: Multi-threaded analysis.</li>
            <li><code>queue</code>: Collecting thread results.</li>
        </ul>

        <h2>Application Overview</h2>
        <p>The application is a command-line tool that processes video files based on user-specified functions. It
            supports three main processing modes:</p>
        <ol start="1">
            <li>
                <p><strong>PROCESS_VIDEO</strong>: Processes a video file using a specialized video processing
                    function.
                </p>
                <ul>
                    <li>
                        <p>Used for debugging and visualizing video processing.</p>
                    </li>
                    <li>
                        <p>Steps:</p>
                        <ol start="1">
                            <li>
                                <p><code>get_scoreboard_coordinates(frame)</code>: Identifies the coordinates of the
                                    scoreboard in the
                                    video frame.</p>
                            </li>
                            <li>
                                <p><code>extract_scoreboard(frame, x1, y1, x2, y2)</code>: Extracts the scoreboard
                                    region from the
                                    frame.</p>
                            </li>
                            <li>
                                <p><code>find_scores(extracted_image)</code>: Detects scores from the extracted
                                    scoreboard image.</p>
                            </li>
                            <li>
                                <p><code>convert_to_abs_coordinates(x1, y1, score_cords)</code>: Converts relative
                                    score
                                    coordinates to
                                    absolute coordinates.</p>
                            </li>
                            <li>
                                <p><code>plotscores_on_images(frame, abs_cords)</code>: Overlays the detected scores
                                    on
                                    the video frame.
                                </p>
                            </li>
                            <li>
                                <p><code>add_timestamp_to_frame(frame, timestamp)</code>: Adds a timestamp to the
                                    frame.
                                </p>
                            </li>
                            <li>
                                <p>The processed frame is streamed to the user for debugging.</p>
                            </li>
                        </ol>


                    </li>
                </ul>
            </li>
            <li>
                <p><strong>PROCESS_FILE</strong>: Processes a video file using a single-threaded approach.</p>
                <ul>
                    <li>
                        <p>Processes a video file to detect highlights.</p>
                    </li>
                    <li>
                        <p>Steps:</p>
                        <ol start="1">
                            <li>
                                <p><code>fetch_score_coords(filepath)</code>: Fetches the coordinates of the
                                    scoreboard
                                    in the video.
                                </p>
                            </li>
                            <li>
                                <p><code>analyze_segment(filepath, cords, 0)</code>: Analyzes the video segment to
                                    detect successful shots.</p>
                            </li>
                            <li>
                                <p><code>process_results(filepath, results)</code>: Create individual clips.</p>
                            </li>
                            <li>
                                <p>Returns control to the script.</p>
                            </li>
                        </ol>
                    </li>
                </ul>
            </li>
            <li>
                <p><strong>PROCESS_FILE_MULTI_THREAD</strong>: Processes a video file using a multi-threaded
                    approach
                    for
                    improved performance.</p>
                <ol start="1">
                    <li>
                        <p><code>fetch_score_coords(filepath)</code>: Fetches the coordinates of the scoreboard.</p>
                    </li>
                    <li>
                        <p><code>split_video(filepath, SEGMENT_SIZE, tempfolder, "segments_%03d.mp4")</code>: Splits
                            the
                            video into
                            smaller segments for parallel processing.</p>
                    </li>
                    <li>
                        <p><code>analyze_segments_with_threads(tempfolder, cords)</code>: Analyzes the video
                            segments
                            concurrently using
                            multiple threads.</p>
                    </li>
                    <li>
                        <p><code>sorted(results)</code>: Sorts the results from all threads.</p>
                    </li>
                    <li>
                        <p><code>process_results(filepath, results)</code>: Processes the results.</p>
                    </li>
                    <li>
                        <p>Returns control to the script.</p>
                    </li>
                </ol>
            </li>
        </ol>
        <img src="Images/CLIP_GENIUS_2.svg" alt="">
        <h2>Modules</h2>
        <ul style="margin-bottom: 2px;">
            <li>
                <p><strong><code>Processor</code></strong>:</p>
                <ul style="margin-bottom: 2px;">
                    <li>
                        <p>Contains the core processing functions: <code>PROCESS_VIDEO</code>,
                            <code>PROCESS_FILE</code>, and
                            <code>PROCESS_FILE_MULTI_THREAD</code>.
                        </p>
                    </li>
                </ul>
            </li>
            <li>
                <p><strong><code>ImageProcessingFunctions</code></strong>:</p>
                <ul style="margin-bottom: 2px;">
                    <li>
                        <p>Contains functions for scoreboard detection, score extraction, and image manipulation.
                        </p>
                    </li>
                </ul>
            </li>
            <li>
                <p><strong><code>PreProcessing</code></strong>:</p>
                <ul style="margin-bottom: 2px;">
                    <li>
                        <p>Contains functions for splitting videos and processing results.</p>
                    </li>
                </ul>
            </li>
            <li>
                <p><strong><code>MultiProcessing</code></strong>:</p>
                <ul style="margin-bottom: 2px;">
                    <li>
                        <p>Contains functions for multi-threaded video segment analysis.</p>
                    </li>
                </ul>
            </li>
        </ul>



        <h2>Process</h2>
        <p>The video processing method involves several key steps, using necessary libraries like OpenCV,
            PyTesseract,
            ffmeg and others
        </p>
        <p>The process starts by opening the video file with cv.VideoCapture. If the video can't be opened, an error
            is
            shown. The video is then processed one frame at a time, and each frame is resized to a 512x512 for
            effective
            computation. The area
            of the
            scoreboard is found using get_scoreboard_coordinates, which uses edge detection and Hough Line Transform
            to
            find horizontal lines. If the horizonta lines are found, the scoreboard area is extracted using
            extract_scoreboard.
        </p>
        <p>
            OCR is then used on the extracted scoreboard area with pytesseract to read scores (i.e. Digists) with a
            set
            confidence level (CONFIDENCE_THRESHOLD set as 75). The position of these scores is changed to absolute
            coordinates. For the next frames, the detected scores are added to the
            video using plotscores_on_images, and a rectangle is drawn around the scoreboard for clarity. A
            timestamp is
            also added to each frame using add_timestamp_to_frame.</p>
        <p>The coordinates obtained from the previous module are used to crop the image and track scores and monitor
            the
            game. This
            approach reduces the need for heavy computations by processing only the necessary pixels, ensuring the
            system stays fast
            and efficient.</p>
        <div class="grid grid-cols-3 items-center">
            <img src="Images/grayscale.png" alt="">
            <img src="Images/edges.png" alt="" srcset="">
            <img src="Images/marked.png" alt="" srcset="">
        </div>



        <h2>Test Cases</h2>
        <h3>Scoreboard Detection</h3>
        <ul>
            <li>
                <p><strong>Input</strong>: A video file with a visible scoreboard.</p>
            </li>
            <li>
                <p><strong>Expected Output</strong>: The application detects the scoreboard region and returns its
                    bounding box
                    coordinates.</p>
            </li>
            <li>
                <p><strong>Result</strong>: The scoreboard was detected with an accuracy of different videos.
                </p>
            </li>
        </ul>
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-0">
            <img src="Images/TestImage6.png" alt="">
            <img src="Images/TestImage1.png" alt="">
            <img src="Images/TestImage2.png" alt="">
            <img src="Images/TestImage3.png" alt="">
            <img src="Images/TestImage4.png" alt="">
            <img src="Images/TestImage5.png" alt="">

        </div>
        <h3>Real-Time Frame Analysis</h3>
        <ul>
            <li>
                <p><strong>Input</strong>: A video file with multiple score changes.</p>
            </li>
            <li>
                <p><strong>Expected Output</strong>: The application detects score changes and records the timestamps.
                </p>
            </li>
            <li>
                <p><strong>Result</strong>: All score changes were detected, and timestamps were recorded correctly.</p>
            </li>
        </ul>
        <video class="rounded-xl mb-10" src="Images/FinalOutput.mp4" type="video/mp4"></video>
        <h3>Highlight Clip Generation</h3>
        <ul>
            <li>
                <p><strong>Input</strong>: A video file and a list of timestamps for score changes.</p>
            </li>
            <li>
                <p><strong>Expected Output</strong>: The application generates highlight clips around the detected score
                    changes.</p>
            </li>
            <li>
                <p><strong>Result</strong>: Highlight clips were generated successfully, including the configured pre-
                    and
                    post-event time.</p>
            </li>
        </ul>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-3">
            <video class="rounded-xl" src="Images/Final_clip_0.mp4" type="video/mp4"></video>
            <video class="rounded-xl" src="Images/Final_clip_1.mp4" type="video/mp4"></video>
            <video class="rounded-xl lg:ml-[50%]" src="Images/Final_clip_2.mp4" type="video/mp4"></video>
        </div>

        <h2>Links</h2>
        <ul>
            <li><a href="https://github.com/RobertmPevec/Clip_Genius"><strong>Github</strong></a></li>
        </ul>


        <h2>Next Iteration Plan</h2>
        <ul>
            <li>Integrate advanced OCR engines (e.g., Google Vision API or AWS Textract) for improved text recognition
            </li>
            <li>Increase the accuracy of score extraction from the scoreboard region</li>
            <li>Enable cloud-based video processing and storage for scalability.</li>
        </ul>
    </main>

    <script src="https://jayd719.github.io/assets/reports/reportV3.js"></script>
    <script>
        appendCDNToMediaElements('https://raw.githubusercontent.com/jayd719/jayd719.github.io/b5cb4160a7f6dca5d8d6bfc2c65d57fc69ef2167/assets/LaurierAnalytics/');
    </script>

</body>

</html>