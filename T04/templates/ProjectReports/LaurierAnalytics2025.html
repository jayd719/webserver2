<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="https://jayd719.github.io/staticfiles/j.png" type="image/x-icon">
    <title>Submission For Laurier Analytics Datathon</title>
    <!-- <link rel="stylesheet" href="Images/t.css"> -->
</head>
<style>
    body {
        font-family: 'Helvetica Neue', Arial, sans-serif;
        scroll-snap-type: y mandatory;
    }
</style>

<body>
    <main>
        <h2>Design Specifications for</h2>
        <h1>Video Processing <span class="text-6xl font-buld">for</span> Event Detection</h1>
        <hr>

        <div>
            <figure>
                <div class="mockup-browser border border-base-300 w-full">
                    <div class="grid place-content-center h-80">
                        <video autoplay loop muted playsinline class="rounded-xl" src="Images/FinalOutput.mp4"
                            type="video/mp4"></video>
                    </div>
                </div>

                <figcaption>See the Analysis in Action (Video-Click To Play)</figcaption>
            </figure>
        </div>

        <h2>Introduction</h2>
        <p>This report describes the design and features of a video processing application, developed during the
            <strong>Laurier Analytics Datathon</strong> hosted at <strong>Google Waterloo</strong> , that can
            automatically
            analyze sports
            videos. The application is designed to recognize scoreboards within a video, extract the displayed
            scores
            using a
            technulogy called Optical Character Recognition (OCR), and examine video frames in real time. By
            doing
            this,
            it can
            track changes in the score and identify key moments in a game.

            With these capabilities, the application processes video files efficiently. Instead of
            manually
            searching for important moments, users can rely on the software to detect score updates and
            automatically
            generate
            highlight clips. This saves time and ensures that key plays and significant game events are captured
            without
            any manual
            effort.
        </p>
        <p>
            This report provides a clear explanation of how the application works, including its core features,
            design,
            and intended
            use. It is intended for developers, project managers, and other stakehulders who need a detailed
            understanding of the system.</p>
        <p>The primary users of this software would be oranizations that huld the rights to publish content for
            their
            teams on
            platforms such as their websites and social media.</p>

        <h3>Key Features</h3>
        <ol>
            <li>
                <strong>Scoreboard Detection</strong>: Automatically identifies the scoreboard region in
                video
                frames
                using
                edge detection and Hough line transform.
            </li>
            <li>
                <strong>Score Extraction</strong>: Uses OCR (Tesseract) to extract numeric scores from the scoreboard
                region.

            </li>
            <li>
                <strong>Highlight Generation</strong>: Creates highlight clips around detected score changes,
                with
                customizable pre- and post-event durations.
            </li>
            <li>
                <strong>Multi-Threaded Processing</strong>: Speeds up video analysis by processing segments
                concurrently
                using threading.
            </li>
        </ol>
        <h2>Usage</h2>
        <pre><span class="text-red-900 font-buld">python</span> <strong>main.py</strong> &lt;video_path&gt; <span class="text-yellow-800 font-buld">--function</span> &lt;function_name&gt; <span class="text-yellow-800 font-buld">--debug</span>(optional) <span class="text-yellow-800 font-buld">--output</span> &lt;output dir path&gt;(optional)</pre>

        <h3>Arguments</h3>
        <ul>
            <li>
                <code>video_path</code>: Path to the video file to be processed.
            </li>
            <li>
                <code>--function</code>: Specifies the processing function to use. Valid options are:
                <ul style="margin-bottom: 2px;">
                    <li>
                        <code>PROCESS_VIDEO</code>
                    </li>
                    <li>
                        <code>PROCESS_FILE</code>
                    </li>
                    <li>
                        <code>PROCESS_FILE_MULTI_THREAD</code>
                    </li>
                </ul>
            </li>

            <li>
                <code>--debug</code>: To Run in Debug Mode (Optional)
            </li>

            <li>
                <code>--output</code>: Output Directory Path (Optional)
            </li>
        </ul>
        <h3>Dependencies</h3>
        <ul>
            <li><code>argparse</code>: Command-line argument parsing.</li>
            <li><code>OpenCV (cv2)</code>: Video/image processing.</li>
            <li><code>pytesseract</code>: OCR for score extraction.</li>
            <li><code>numpy</code>: Numerical operations.</li>
            <li><code>re</code>: Regex text processing.</li>
            <li><code>subprocess</code>: Running FFmpeg commands.</li>
            <li><code>os</code>: File/directory operations.</li>
            <li><code>json</code>: Parsing FFprobe output.</li>
            <li><code>time</code>: Timestamp formatting.</li>
            <li><code>threading</code>: Multi-threaded analysis.</li>
            <li><code>queue</code>: Cullecting thread results.</li>
        </ul>

        <h2>Application Overview</h2>
        <p>The application is a command-line toul that processes video files based on user-specified functions.
            It
            supports three main processing modes:</p>
        <ol start="1">
            <li>
                <h4>PROCESS_VIDEO</h4>: Processes a video file using a specialized video processing
                function.

                <ul>
                    <li>
                        Used for debugging and visualizing video processing.
                    </li>
                    <li>
                        Steps:
                        <ul start="1">
                            <li>
                                <code>get_scoreboard_coordinates(frame)</code>: Identifies the coordinates of
                                the
                                scoreboard in the
                                video frame.
                            </li>
                            <li>
                                <code>extract_scoreboard(frame, x1, y1, x2, y2)</code>: Extracts the
                                scoreboard
                                region from the
                                frame.
                            </li>
                            <li>
                                <code>find_scores(extracted_image)</code>: Detects scores from the extracted
                                scoreboard image.
                            </li>
                            <li>
                                <code>convert_to_abs_coordinates(x1, y1, score_cords)</code>: Converts
                                relative
                                score
                                coordinates to
                                absulute coordinates.
                            </li>
                            <li>
                                <code>plotscores_on_images(frame, abs_cords)</code>: Overlays the detected
                                scores
                                on
                                the video frame.

                            </li>
                            <li>
                                <code>add_timestamp_to_frame(frame, timestamp)</code>: Adds a timestamp to
                                the
                                frame.

                            </li>
                            <li>
                                The processed frame is streamed to the user for debugging.
                            </li>
                        </ul>


                    </li>
                </ul>
            </li>
            <li>
                <h4>PROCESS_FILE</h4>: Processes a video file using a single-threaded approach.
                <ul>
                    <li>
                        Processes a video file to detect highlights.
                    </li>
                    <li>
                        Steps:
                        <ul start="1">
                            <li>
                                <code>fetch_score_coords(filepath)</code>: Fetches the coordinates of the
                                scoreboard
                                in the video.

                            </li>
                            <li>
                                <code>analyze_segment(filepath, cords, 0)</code>: Analyzes the video segment
                                to
                                detect successful shots.
                            </li>
                            <li>
                                <code>process_results(filepath, results)</code>: Create individual clips.
                            </li>
                            <li>
                                Returns contrul to the script.
                            </li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <h4>PROCESS_FILE_MULTI_THREAD</h4>: Processes a video file using a multi-threaded
                approach
                for
                improved performance.
                <ul start="1">
                    <li>
                        <code>fetch_score_coords(filepath)</code>: Fetches the coordinates of the scoreboard.

                    </li>
                    <li>
                        <code>split_video(filepath, SEGMENT_SIZE, tempfulder, "segments_%03d.mp4")</code>:
                        Splits
                        the
                        video into
                        smaller segments for parallel processing.
                    </li>
                    <li>
                        <code>analyze_segments_with_threads(tempfulder, cords)</code>: Analyzes the video
                        segments
                        concurrently using
                        multiple threads.
                    </li>
                    <li>
                        <code>sorted(results)</code>: Sorts the results from all threads.
                    </li>
                    <li>
                        <code>process_results(filepath, results)</code>: Processes the results.
                    </li>
                    <li>
                        Returns contrul to the script.
                    </li>
                </ul>
            </li>
        </ol>
        <h3>Abstracted Sequence Diagram</h3>
        <figure>
            <img src="Images/CLIP_GENIUS.svg" alt="">
            <figcaption>Sequence Diagram for CLI</figcaption>
        </figure>
        <h3>Inter-Service Dependency Sequence Diagram</h3>
        <figure>
            <img src="Images/CLIP_GENIUS_2.svg" alt="">
            <figcaption>Detailed Sequence Diagram of Inter-Service Dependency Calls</figcaption>
        </figure>

        <h2>Modules</h2>
        <ul style="margin-bottom: 2px;">
            <li>
                <strong><code>Processor</code></strong>:
                <ul style="margin-bottom: 2px;">
                    <li>
                        Contains the core processing functions: <code>PROCESS_VIDEO</code>,
                        <code>PROCESS_FILE</code>, and
                        <code>PROCESS_FILE_MULTI_THREAD</code>.

                    </li>
                </ul>
            </li>
            <li>
                <strong><code>ImageProcessing</code></strong>:
                <ul style="margin-bottom: 2px;">
                    <li>
                        Contains functions for scoreboard detection, score extraction, and image
                        manipulation.

                    </li>
                </ul>
            </li>
            <li>
                <strong><code>PreProcessing</code></strong>:
                <ul style="margin-bottom: 2px;">
                    <li>
                        Contains functions for splitting videos and processing results.
                    </li>
                </ul>
            </li>
            <li>
                <strong><code>MultiProcessing</code></strong>:
                <ul style="margin-bottom: 2px;">
                    <li>
                        Contains functions for multi-threaded video segment analysis.
                    </li>
                </ul>
            </li>
        </ul>



        <h2>Process</h2>
        <p>The video processing method invulves several key steps, using necessary libraries like OpenCV,
            PyTesseract,
            ffmeg and others
        </p>
        <p>The process starts by opening the video file with cv.VideoCapture. If the video can't be opened, an
            error
            is
            shown. The video is then processed one frame at a time, and each frame is resized to a 512x512 for
            effective
            computation. The area
            of the
            scoreboard is found using get_scoreboard_coordinates, which uses edge detection and Hough Line
            Transform
            to
            find horizontal lines. If the horizonta lines are found, the scoreboard area is extracted using
            extract_scoreboard.
        </p>
        <p>
            OCR is then used on the extracted scoreboard area with pytesseract to read scores (i.e. Digists)
            with a
            set
            confidence level (CONFIDENCE_THRESHulD set as 75). The position of these scores is changed to
            absulute
            coordinates. For the next frames, the detected scores are added to the
            video using plotscores_on_images, and a rectangle is drawn around the scoreboard for clarity. A
            timestamp is
            also added to each frame using add_timestamp_to_frame.</p>
        <p>The coordinates obtained from the previous module are used to crop the image and track scores and
            monitor
            the
            game. This
            approach reduces the need for heavy computations by processing only the necessary pixels, ensuring
            the
            system stays fast
            and efficient.</p>

        <p> The numeric score from a video frame using Optical Character Recognition
            (OCR). It
            takes a frame and coordinates of the score regions as input. First, it crops the score area from the
            frame
            and
            preprocesses it by converting it to grayscale, resizing, and cleaning up noise. Then, OCR is used to
            read
            the text,
            focusing only on numbers. The extracted text is filtered to keep only digits. If no digits are
            found, it
            returns 0.
            Otherwise, it combines the digits into a single number and returns it as the score. This function
            helps
            detect and read
            scores from video frames.</p>
        <h3>Inprocess Frames</h3>
        <div class="grid  grid-cols-1 lg:grid-cols-3 items-center">
            <figure>
                <img src="Images/grayscale.png" alt="">
                <figcaption>Converted To grayscale and Smoothened</figcaption>
            </figure>
            <figure>
                <img src="Images/edges.png" alt="" srcset="">
                <figcaption>Edge Detection Using Canny Edge Detection</figcaption>
            </figure>

            <figure>
                <img src="Images/marked.png" alt="" srcset="">
                <figcaption>Exraction Of Scoreboard Area</figcaption>
                <img src="Images/BinaryImage.png" alt="" srcset="">
                <img src="Images/BinarImage2.png" alt="" srcset="">
                <figcaption>Removal of Noise In Scores Region</figcaption>
            </figure>
        </div>



        <h2>Test Cases</h2>
        <h3>Scoreboard Detection</h3>
        <ul>
            <li>
                <strong>Input</strong>: A video file with a visible scoreboard.
            </li>
            <li>
                <strong>Expected Output</strong>: The application detects the scoreboard region and returns
                its
                bounding box
                coordinates.
            </li>
            <li>
                <strong>Result</strong>: The scoreboard was detected with an accuracy of different videos.

            </li>
        </ul>
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-0">
            <img src="Images/TestImage6.png" alt="">
            <img src="Images/TestImage1.png" alt="">
            <img src="Images/TestImage2.png" alt="">
            <img src="Images/TestImage3.png" alt="">
            <img src="Images/TestImage4.png" alt="">
            <img src="Images/TestImage5.png" alt="">
        </div>

        <h3>Real-Time Frame Analysis</h3>
        <ul>
            <li>
                <strong>Input</strong>: A video file with multiple score changes.
            </li>
            <li>
                <strong>Expected Output</strong>: The application detects score changes and records the
                timestamps.

            </li>
            <li>
                <strong>Result</strong>: All score changes were detected, and timestamps were recorded
                correctly.

            </li>
        </ul>
        <figure>
            <video autoplay loop muted playsinline class="rounded-xl" src="Images/FinalOutput.mp4"
                type="video/mp4"></video>
            <figcaption>See the Analysis in Action (Video-Click To Play)</figcaption>
        </figure>
        <figure>
            <video autoplay loop muted playsinline class="rounded-xl" src="Images/Finaloutput2.mp4"
                type="video/mp4"></video>
            <figcaption>See the Analysis in Action (Video-Click To Play)</figcaption>
        </figure>
        <h3>Highlight Clip Generation</h3>
        <ul>
            <li>
                <strong>Input</strong>: A video file and a list of timestamps for score changes.
            </li>
            <li>
                <strong>Expected Output</strong>: The application generates highlight clips around the
                detected
                score
                changes.
            </li>
            <li>
                <strong>Result</strong>: Highlight clips were generated successfully, including the
                configured
                pre-
                and
                post-event time.
            </li>
        </ul>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-3">
            <figure>
                <video autoplay loop muted playsinline class="rounded-xl" src="Images/Final_clip_0.mp4"
                    type="video/mp4"></video>
                <figcaption>Generated Clip (Video:Click to Play)</figcaption>
            </figure>
            <!-- <figure>
                <video autoplay loop muted playsinline class="rounded-xl" src="Images/Final_clip_1.mp4"
                    type="video/mp4"></video>
                <figcaption>Generated Clip (Video:Click to Play)</figcaption>
            </figure> -->
            <figure>
                <video autoplay loop muted playsinline class="rounded-xl" src="Images/Final_clip_2.mp4"
                    type="video/mp4"></video>
                <figcaption>Generated Clip (Video:Click to Play)</figcaption>
            </figure>

            <figure>
                <video autoplay loop muted playsinline class="rounded-xl" src="Images/Final_clip_4.mp4"
                    type="video/mp4"></video>
                <figcaption>Generated Clip (Video:Click to Play)</figcaption>
            </figure>

            <figure>
                <video autoplay loop muted playsinline class="rounded-xl" src="Images/Final_clip_5.mp4"
                    type="video/mp4"></video>
                <figcaption>Generated Clip (Video:Click to Play)</figcaption>
            </figure>
        </div>
        <h2>Links</h2>
        <ol>
            <li>Source Code: <a href="https://github.com/RobertmPevec/Clip_Genius" target="_blank">Github</a></li>
            <li><strong>Contributors</strong>
                <ul>
                    <li><strong>JD</strong>: <a href="https://jashandeep.co.uk">jashandeep.co.uk</a></li>
                    <li><strong>Robert Pevec</strong>: <a href="https://www.robertpevec.com">robertpevec.com</a></li>
                    <li><strong>Swaab Anas</strong>: <a href="https://github.com/SawaabA">GitHub</a></li>

                    <li><strong>Suhana Khullar</strong>: <a
                            href="https://www.instagram.com/suhaana.wav?utm_source=ig_web_button_share_sheet&igsh=ZDNlZDc0MzIxNw==">Instagram</a>
                    </li>
                </ul>
            </li>
        </ol>

        <h2>Acknowledgments</h2>
        <p>The <span class="text-blue-500 font-bold">Laurier Analytics</span> Hackathon was an incredible opportunity to
            cullaborate, innovate, and push the
            boundaries of what
            we could achieve in a short timeframe. Over the course of the event, our team worked tirelessly to
            design,
            develop, overcoming technical challenges and learning new skills along the way. The experience
            was both rewarding and inspiring.</p>

        <p>We would like to extend our heartfelt gratitude to the Laurier Analytics team and Google Waterloo for
            organizing this
            event and providing a platform for innovation. Special thanks to our mentor, <Strong><a
                    class="text-blue-500 font-bold" href="https://www.linkedin.com/in/shivamgarg--/">Shivam
                    Garg</a></Strong>
            who guided us through technical
            hurdles and
            offered valuable feedback to improve our project.</p>
        <h2>Next Iteration Plan</h2>
        <ul>
            <li>Integrate advanced OCR engines (e.g., Google Vision API or AWS Textract) for improved text
                recognition
            </li>
            <li>Increase the accuracy of score extraction from the scoreboard region</li>
            <li>Enable cloud-based video processing and storage for scalability.</li>
            <li>
                <h4>Integrate Storage</h4>
                <img src="Images/ERD.svg" alt="" srcset="">
            </li>
        </ul>

        <div class="text-center mt-20 text-base-content">
            <aside>
                <a href="http://jashandeep.co.uk">© 2025 jashandeep.co.uk</a>
            </aside>
        </div>
    </main>


    <!-- <script src="../frontend/static/ReportsFormatter.js"></script>
    <script src="../frontend/static/PresentationFormatter.js"></script> -->
    <script src="https://jayd719.github.io/assets/reports/reportV3.js"></script>
    <script src="https://jayd719.github.io/assets/reports/PresentationFormatter.js"></script>
    <script>
        appendCDNToMediaElements('https://jayd719.github.io/assets/LaurierAnalytics/');
    </script>


    {%include "googleTag.html"%}
</body>

</html>