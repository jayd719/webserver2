<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Video Processing & Highlight
        Generation</title>
</head>
<style>
    body {
        font-family: 'Helvetica Neue', Arial, sans-serif;
    }
</style>

<body>
    <main>
        <h1>Design Specification Document for</h1>
        <span class="text-6xl mb-[50px] font-bold">Video Processing & Highlight
            Generation</span>
        <hr>

        <div>
            <video autoplay loop muted playsinline class="rounded-xl" src="Images/FinalOutput.mp4"
                type="video/mp4"></video>
        </div>
        <h2>Introduction</h2>
        <p>This report describes the design and features of a video processing application that can automatically
            analyze sports
            videos. The application is designed to recognize scoreboards within a video, extract the displayed scores
            using a
            technology called Optical Character Recognition (OCR), and examine video frames in real time. By doing this,
            it can
            track changes in the score and identify key moments in a game.

            With these capabilities, the application processes video files efficiently. Instead of
            manually
            searching for important moments, users can rely on the software to detect score updates and automatically
            generate
            highlight clips. This saves time and ensures that key plays and significant game events are captured without
            any manual
            effort.
        </p>
        <p>
            This report provides a clear explanation of how the application works, including its core features, design,
            and intended
            use. It is intended for developers, project managers, and other stakeholders who need a detailed
            understanding of the
            system.</p>
        <p>The primary users of this software would be oranizations that hold the rights to publish content for their
            teams on
            platforms such as their websites and social media.</p>

        <h2>Usage</h2>
        <img src="Images/CLIP_GENIUS.svg" alt="">
        <pre>python main.py &lt;video_path&gt; --function &lt;function_name&gt;</pre>
        <h3>Arguments</h3>
        <ul>
            <li>
                <p><code>video_path</code>: Path to the video file to be processed.</p>
            </li>
            <li>
                <p><code>--function</code>: Specifies the processing function to use. Valid options are:</p>
                <ul>
                    <li>
                        <p><code>PROCESS_VIDEO</code></p>
                    </li>
                    <li>
                        <p><code>PROCESS_FILE</code></p>
                    </li>
                    <li>
                        <p><code>PROCESS_FILE_MULTI_THREAD</code></p>
                    </li>
                </ul>
            </li>
        </ul>
        <h3>Dependencies</h3>
        <ul>
            <li><code>argparse</code>: Command-line argument parsing.</li>
            <li><code>OpenCV (cv2)</code>: Video/image processing.</li>
            <li><code>pytesseract</code>: OCR for score extraction.</li>
            <li><code>numpy</code>: Numerical operations.</li>
            <li><code>re</code>: Regex text processing.</li>
            <li><code>subprocess</code>: Running FFmpeg commands.</li>
            <li><code>os</code>: File/directory operations.</li>
            <li><code>json</code>: Parsing FFprobe output.</li>
            <li><code>time</code>: Timestamp formatting.</li>
            <li><code>threading</code>: Multi-threaded analysis.</li>
            <li><code>queue</code>: Collecting thread results.</li>
        </ul>

        <h2>Application Overview</h2>
        <p>The application is a command-line tool that processes video files based on user-specified functions. It
            supports three main processing modes:</p>
        <ol start="1">
            <li>
                <p><strong>PROCESS_VIDEO</strong>: Processes a video file using a specialized video processing
                    function.
                </p>
                <ul>
                    <li>
                        <p>Used for debugging and visualizing video processing.</p>
                    </li>
                    <li>
                        <p>Steps:</p>
                        <ol start="1">
                            <li>
                                <p><code>get_scoreboard_coordinates(frame)</code>: Identifies the coordinates of the
                                    scoreboard in the
                                    video frame.</p>
                            </li>
                            <li>
                                <p><code>extract_scoreboard(frame, x1, y1, x2, y2)</code>: Extracts the scoreboard
                                    region from the
                                    frame.</p>
                            </li>
                            <li>
                                <p><code>find_scores(extracted_image)</code>: Detects scores from the extracted
                                    scoreboard image.</p>
                            </li>
                            <li>
                                <p><code>convert_to_abs_coordinates(x1, y1, score_cords)</code>: Converts relative
                                    score
                                    coordinates to
                                    absolute coordinates.</p>
                            </li>
                            <li>
                                <p><code>plotscores_on_images(frame, abs_cords)</code>: Overlays the detected scores
                                    on
                                    the video frame.
                                </p>
                            </li>
                            <li>
                                <p><code>add_timestamp_to_frame(frame, timestamp)</code>: Adds a timestamp to the
                                    frame.
                                </p>
                            </li>
                            <li>
                                <p>The processed frame is streamed to the user for debugging.</p>
                            </li>
                        </ol>


                    </li>
                </ul>
            </li>
            <li>
                <p><strong>PROCESS_FILE</strong>: Processes a video file using a single-threaded approach.</p>
                <ul>
                    <li>
                        <p>Processes a video file to detect highlights.</p>
                    </li>
                    <li>
                        <p>Steps:</p>
                        <ol start="1">
                            <li>
                                <p><code>fetch_score_coords(filepath)</code>: Fetches the coordinates of the
                                    scoreboard
                                    in the video.
                                </p>
                            </li>
                            <li>
                                <p><code>analyze_segment(filepath, cords, 0)</code>: Analyzes the video segment to
                                    detect successful shots.</p>
                            </li>
                            <li>
                                <p><code>process_results(filepath, results)</code>: Create individual clips.</p>
                            </li>
                            <li>
                                <p>Returns control to the script.</p>
                            </li>
                        </ol>
                    </li>
                </ul>
            </li>
            <li>
                <p><strong>PROCESS_FILE_MULTI_THREAD</strong>: Processes a video file using a multi-threaded
                    approach
                    for
                    improved performance.</p>
                <ol start="1">
                    <li>
                        <p><code>fetch_score_coords(filepath)</code>: Fetches the coordinates of the scoreboard.</p>
                    </li>
                    <li>
                        <p><code>split_video(filepath, SEGMENT_SIZE, tempfolder, "segments_%03d.mp4")</code>: Splits
                            the
                            video into
                            smaller segments for parallel processing.</p>
                    </li>
                    <li>
                        <p><code>analyze_segments_with_threads(tempfolder, cords)</code>: Analyzes the video
                            segments
                            concurrently using
                            multiple threads.</p>
                    </li>
                    <li>
                        <p><code>sorted(results)</code>: Sorts the results from all threads.</p>
                    </li>
                    <li>
                        <p><code>process_results(filepath, results)</code>: Processes the results.</p>
                    </li>
                    <li>
                        <p>Returns control to the script.</p>
                    </li>
                </ol>
            </li>
        </ol>
        <img src="Images/CLIP_GENIUS_2.svg" alt="">
        <h2>Modules</h2>
        <ul style="margin-bottom: 2px;">
            <li>
                <p><strong><code>Processor</code></strong>:</p>
                <ul style="margin-bottom: 2px;">
                    <li>
                        <p>Contains the core processing functions: <code>PROCESS_VIDEO</code>,
                            <code>PROCESS_FILE</code>, and
                            <code>PROCESS_FILE_MULTI_THREAD</code>.
                        </p>
                    </li>
                </ul>
            </li>
            <li>
                <p><strong><code>ImageProcessingFunctions</code></strong>:</p>
                <ul style="margin-bottom: 2px;">
                    <li>
                        <p>Contains functions for scoreboard detection, score extraction, and image manipulation.
                        </p>
                    </li>
                </ul>
            </li>
            <li>
                <p><strong><code>PreProcessing</code></strong>:</p>
                <ul style="margin-bottom: 2px;">
                    <li>
                        <p>Contains functions for splitting videos and processing results.</p>
                    </li>
                </ul>
            </li>
            <li>
                <p><strong><code>MultiProcessing</code></strong>:</p>
                <ul style="margin-bottom: 2px;">
                    <li>
                        <p>Contains functions for multi-threaded video segment analysis.</p>
                    </li>
                </ul>
            </li>
        </ul>



        <h2>Process</h2>
        <p>The video processing method involves several key steps, using necessary libraries like OpenCV,
            PyTesseract,
            ffmeg and others
        </p>
        <p>The process starts by opening the video file with cv.VideoCapture. If the video can't be opened, an error
            is
            shown. The video is then processed one frame at a time, and each frame is resized to a 512x512 for
            effective
            computation. The area
            of the
            scoreboard is found using get_scoreboard_coordinates, which uses edge detection and Hough Line Transform
            to
            find horizontal lines. If the horizonta lines are found, the scoreboard area is extracted using
            extract_scoreboard.
        </p>
        <p>
            OCR is then used on the extracted scoreboard area with pytesseract to read scores (i.e. Digists) with a
            set
            confidence level (CONFIDENCE_THRESHOLD set as 75). The position of these scores is changed to absolute
            coordinates. For the next frames, the detected scores are added to the
            video using plotscores_on_images, and a rectangle is drawn around the scoreboard for clarity. A
            timestamp is
            also added to each frame using add_timestamp_to_frame.</p>
        <p>The coordinates obtained from the previous module are used to crop the image and track scores and monitor
            the
            game. This
            approach reduces the need for heavy computations by processing only the necessary pixels, ensuring the
            system stays fast
            and efficient.</p>

        <p> The numeric score from a video frame using Optical Character Recognition
            (OCR). It
            takes a frame and coordinates of the score regions as input. First, it crops the score area from the frame
            and
            preprocesses it by converting it to grayscale, resizing, and cleaning up noise. Then, OCR is used to read
            the text,
            focusing only on numbers. The extracted text is filtered to keep only digits. If no digits are found, it
            returns 0.
            Otherwise, it combines the digits into a single number and returns it as the score. This function helps
            detect and read
            scores from video frames.</p>
        <div class="grid grid-cols-3 items-center">
            <img src="Images/grayscale.png" alt="">
            <img src="Images/edges.png" alt="" srcset="">
            <img src="Images/marked.png" alt="" srcset="">
        </div>



        <h2>Test Cases</h2>
        <h3>Scoreboard Detection</h3>
        <ul>
            <li>
                <p><strong>Input</strong>: A video file with a visible scoreboard.</p>
            </li>
            <li>
                <p><strong>Expected Output</strong>: The application detects the scoreboard region and returns its
                    bounding box
                    coordinates.</p>
            </li>
            <li>
                <p><strong>Result</strong>: The scoreboard was detected with an accuracy of different videos.
                </p>
            </li>
        </ul>
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-0">
            <img src="Images/TestImage6.png" alt="">
            <img src="Images/TestImage1.png" alt="">
            <img src="Images/TestImage2.png" alt="">
            <img src="Images/TestImage3.png" alt="">
            <img src="Images/TestImage4.png" alt="">
            <img src="Images/TestImage5.png" alt="">

        </div>
        <h3>Real-Time Frame Analysis</h3>
        <ul>
            <li>
                <p><strong>Input</strong>: A video file with multiple score changes.</p>
            </li>
            <li>
                <p><strong>Expected Output</strong>: The application detects score changes and records the timestamps.
                </p>
            </li>
            <li>
                <p><strong>Result</strong>: All score changes were detected, and timestamps were recorded correctly.</p>
            </li>
        </ul>
        <video autoplay loop muted playsinline class="rounded-xl mb-10" src="Images/FinalOutput.mp4"
            type="video/mp4"></video>
        <h3>Highlight Clip Generation</h3>
        <ul>
            <li>
                <p><strong>Input</strong>: A video file and a list of timestamps for score changes.</p>
            </li>
            <li>
                <p><strong>Expected Output</strong>: The application generates highlight clips around the detected score
                    changes.</p>
            </li>
            <li>
                <p><strong>Result</strong>: Highlight clips were generated successfully, including the configured pre-
                    and
                    post-event time.</p>
            </li>
        </ul>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-3">
            <video autoplay loop muted playsinline class="rounded-xl" src="Images/Final_clip_0.mp4"
                type="video/mp4"></video>
            <video autoplay loop muted playsinline class="rounded-xl" src="Images/Final_clip_1.mp4"
                type="video/mp4"></video>
            <video autoplay loop muted playsinline class="rounded-xl lg:ml-[50%]" src="Images/Final_clip_2.mp4"
                type="video/mp4"></video>
        </div>

        <h2>Links</h2>
        <ul>
            <li><a href="https://github.com/RobertmPevec/Clip_Genius"><strong>Github</strong></a></li>
        </ul>


        <h2>Next Iteration Plan</h2>
        <ul>
            <li>Integrate advanced OCR engines (e.g., Google Vision API or AWS Textract) for improved text recognition
            </li>
            <li>Increase the accuracy of score extraction from the scoreboard region</li>
            <li>Enable cloud-based video processing and storage for scalability.</li>
        </ul>
    </main>

    <script src="../frontend/static/ReportsFormatter.js"></script>
    <!-- <script src="https://jayd719.github.io/assets/reports/reportV3.js"></script> -->
    <script>
        appendCDNToMediaElements('https://raw.githubusercontent.com/jayd719/jayd719.github.io/b5cb4160a7f6dca5d8d6bfc2c65d57fc69ef2167/assets/LaurierAnalytics/');
    </script>

</body>

</html>